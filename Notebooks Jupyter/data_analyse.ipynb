{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "289934ae",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "Cette étape a pour objectif d’explorer et d’analyser les données contenues dans la base gdelt_benin.db.\n",
    "Elle consiste à examiner les événements collectés afin d’en extraire des tendances, des patterns ou des anomalies, en s’appuyant sur des techniques d’analyse de données.\n",
    "\n",
    "Cette phase permet de mieux comprendre le contenu de la base avant d’envisager des analyses plus poussées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e82dec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pandas matplotlib seaborn scikit-learn python-dotenv pmdarima openai ipython-sql\n",
    "%pip install --upgrade pandas sqlalchemy xgboost plotly dash dash-table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a053d15",
   "metadata": {},
   "source": [
    "## Identification de la thématique de chaque évènement\n",
    "\n",
    "Après la création de la base de données gdelt_benin.db, l’un des objectifs est d’identifier la thématique principale de chaque article présent dans la table benin_events.\n",
    "Le processus suivant, reposant sur l’utilisation d’Azure OpenAI, permet d’analyser le contenu des URL afin d’en extraire le sujet principal abordé dans chaque article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43349ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "from functions.call_openai import call_openai_api\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Chemin vers la base de données\n",
    "output_dir = \"/home/pionner02/Pionner02 UlChris-Project/data\"\n",
    "db_path = os.path.join(output_dir, 'gdelt_benin.db')\n",
    "\n",
    "# Vérification de l'existence du fichier\n",
    "if not os.path.exists(db_path):\n",
    "    print(f\"Fichier introuvable : {db_path}\")\n",
    "    exit(1)\n",
    "\n",
    "# Fonction pour extraire le contenu d'une URL\n",
    "def extract_url_content(url: str, timeout: int = 5) -> str:\n",
    "    try:\n",
    "        response = requests.get(url, timeout=timeout, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            text = ' '.join(p.get_text(strip=True) for p in soup.find_all('p'))[:2000]\n",
    "            return text if text else \"Contenu non pertinent\"\n",
    "        else:\n",
    "            print(f\"URL {url} inaccessible (code {response.status_code})\")\n",
    "            return \"Contenu inaccessible\"\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Erreur lors de l'accès à l'URL {url} : {str(e)}\")\n",
    "        return \"Contenu inaccessible\"\n",
    "\n",
    "# Fonction API avec retry\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
    "def call_openai_with_retry(prompt: str, max_tokens: int = 100) -> str:\n",
    "    return call_openai_api(prompt, max_tokens=max_tokens)\n",
    "\n",
    "# Fonction pour traiter un événement\n",
    "def process_event(event: Tuple[int, str, str, float]) -> Tuple[str, int]:\n",
    "    event_id, source_url, location, tone = event\n",
    "    print(f\"Traitement de l'événement {event_id} - URL : {source_url}\")\n",
    "\n",
    "    content = extract_url_content(source_url)\n",
    "    prompt = (\n",
    "        \"Tu es un expert en analyse de contenu médiatique spécialisé dans les événements au Bénin. \"\n",
    "        \"À partir du contenu extrait de l'URL {source_url}: '{content}', et des informations suivantes : \"\n",
    "        \"lieu de l'événement='{location}', ton moyen={tone}, \"\n",
    "        \"identifie le thème principal de l'événement décrit. \"\n",
    "        \"Le thème doit être une phrase nominale cohérente concise et précise (2 mots au maximum) décrivant précisément le sujet central, \"\n",
    "        \"en lien avec le contexte de la publication (ex. 'CONFLIT', 'ECONOMIE', 'SANTE', 'POLITIQUE', 'CRIME', 'CRISE SOCIALE'). \"\n",
    "        \"Si le contenu est inaccessible ou insuffisant, utilise le lieu et le ton pour inférer un thème plausible. \"\n",
    "        \"Si le contenu est hors sujet (ex. publicité, page d'accueil), retourne 'Contenu non pertinent'. \"\n",
    "        \"Aussi recence toujours le thème en majuscule\"\n",
    "        \"Les thèmes ne doivent pas avoir un forte connotation péjorative mais informative comme un journaliste \"\n",
    "        \"Limite la réponse à 2 mots maximum.\"\n",
    "        \n",
    "    ).format(source_url=source_url, content=content, location=location or \"Bénin\", tone=tone)\n",
    "\n",
    "    try:\n",
    "        theme = call_openai_with_retry(prompt)\n",
    "        if theme.startswith(\"Erreur\"):\n",
    "            print(f\"Événement {event_id} : {theme}\")\n",
    "            theme = \"Thème non identifiable\"\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur API pour l'événement {event_id} : {str(e)}\")\n",
    "        theme = \"Thème non identifiable\"\n",
    "\n",
    "    return (theme, event_id)\n",
    "\n",
    "try:\n",
    "    with sqlite3.connect(db_path) as conn:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"PRAGMA foreign_keys = ON;\")\n",
    "\n",
    "        # Vérifier l'existence de la colonne Themes\n",
    "        try:\n",
    "            cursor.execute(\"ALTER TABLE events ADD COLUMN Themes TEXT;\")\n",
    "            conn.commit()\n",
    "            print(\"Colonne Themes ajoutée.\")\n",
    "        except sqlite3.OperationalError:\n",
    "            print(\"Colonne Themes existe déjà.\")\n",
    "\n",
    "        # Récupérer les URLs non traitées avec location et tone\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT GLOBALEVENTID, SOURCEURL, ActionGeo_FullName, AvgTone\n",
    "            FROM events \n",
    "            WHERE SOURCEURL IS NOT NULL AND Themes IS NULL \n",
    "            LIMIT 100;  -- Limite pour tester\n",
    "        \"\"\")\n",
    "        rows: List[Tuple[int, str, str, float]] = cursor.fetchall()\n",
    "        print(f\"{len(rows)} événements à traiter.\")\n",
    "\n",
    "        # Traiter les événements en parallèle\n",
    "        updates = []\n",
    "        batch_size = 100\n",
    "        max_workers = 5  # Ajuster selon les limites de l'API\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            future_to_event = {executor.submit(process_event, row): row for row in rows}\n",
    "            for future in as_completed(future_to_event):\n",
    "                theme, event_id = future.result()\n",
    "                updates.append((theme, event_id))\n",
    "                print(f\"Événement {event_id} - Thème : {theme}\")\n",
    "\n",
    "                # Mettre à jour par lots\n",
    "                if len(updates) >= batch_size:\n",
    "                    try:\n",
    "                        cursor.executemany(\"UPDATE events SET Themes = ? WHERE GLOBALEVENTID = ?\", updates)\n",
    "                        conn.commit()\n",
    "                        print(f\"{len(updates)} événements mis à jour.\")\n",
    "                        updates = []\n",
    "                    except sqlite3.Error as e:\n",
    "                        print(f\"Erreur lors de la mise à jour : {str(e)}\")\n",
    "\n",
    "        # Mettre à jour les dernières lignes\n",
    "        if updates:\n",
    "            try:\n",
    "                cursor.executemany(\"UPDATE events SET Themes = ? WHERE GLOBALEVENTID = ?\", updates)\n",
    "                conn.commit()\n",
    "                print(f\"{len(updates)} événements mis à jour.\")\n",
    "            except sqlite3.Error as e:\n",
    "                print(f\"Erreur lors de la mise à jour : {str(e)}\")\n",
    "\n",
    "except sqlite3.Error as e:\n",
    "    print(f\"Erreur SQLite : {str(e)}\")\n",
    "finally:\n",
    "    print(\"Traitement terminé. La base de données a été mise à jour avec les thématiques.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813057bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dossier de la base de données SQLite\n",
    "output_dir = \"/home/pionner02/Pionner02 UlChris-Project/data\"\n",
    "db_path = os.path.join(output_dir, 'gdelt_benin.db')\n",
    "\n",
    "# Connexion à la base de données\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Liste des tables à consulter\n",
    "tables = [\n",
    "          'events', \n",
    "          'mentions'\n",
    "          ]\n",
    "\n",
    "# Explorer les tables\n",
    "for table in tables:\n",
    "    try:\n",
    "        # Aperçu des lignes\n",
    "        cursor.execute(f\"SELECT COUNT(*) FROM {table}\")\n",
    "        count = cursor.fetchone()[0]\n",
    "        print(f\"Nombre de lignes dans {table} : {count}\")\n",
    "        \n",
    "        # Aperçu des colonnes\n",
    "        cursor.execute(f\"PRAGMA table_info({table})\")\n",
    "        columns = [info[1] for info in cursor.fetchall()]\n",
    "        print(f\"Colonnes dans {table} : {columns}\\n\")\n",
    "\n",
    "    except sqlite3.OperationalError as e:\n",
    "        print(f\" Erreur avec la table '{table}' : {e}\\n\")\n",
    "\n",
    "# Afficher les index existants dans la base\n",
    "cursor.execute(\"SELECT name, tbl_name FROM sqlite_master WHERE type='index'\")\n",
    "indexes = cursor.fetchall()\n",
    "\n",
    "if indexes:\n",
    "    print(\" Index existants :\")\n",
    "    for idx in indexes:\n",
    "        print(f\" - {idx[0]} (table : {idx[1]})\")\n",
    "else:\n",
    "    print(\" Aucun index existant trouvé.\")\n",
    "conn.close()\n",
    "print(\"\\n Connexion à la base fermée.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3d1a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from contextlib import closing\n",
    "\n",
    "# Connexion avec sqlalchemy pour %sql et pandas\n",
    "engine = create_engine(f\"sqlite:///{db_path}\")\n",
    "\n",
    "# Fonction pour récupérer un aperçu de la table\n",
    "def preview_table(table_name, limit=10):\n",
    "    query = f\"SELECT * FROM {table_name} LIMIT {limit}\"\n",
    "    return pd.read_sql(query, engine)\n",
    "\n",
    "# Fonction pour afficher la structure de la table\n",
    "def show_table_structure(table_name):\n",
    "    query = f\"PRAGMA table_info({table_name})\"\n",
    "    return pd.read_sql(query, engine)\n",
    "\n",
    "# Aperçu des 5 premières lignes de la table 'events'\n",
    "print(\"Aperçu de la table 'events' :\")\n",
    "events_df = preview_table('events')\n",
    "display(events_df)\n",
    "\n",
    "# Structure de la table 'events' (noms des colonnes et types)\n",
    "print(\"\\nStructure de la table 'events' :\")\n",
    "events_structure = show_table_structure('events')\n",
    "display(events_structure)\n",
    "\n",
    "# Aperçu des 5 premières lignes de la table 'mentions'\n",
    "print(\"\\nAperçu de la table 'mentions' :\")\n",
    "mentions_df = preview_table('mentions')\n",
    "display(mentions_df)\n",
    "\n",
    "# Structure de la table 'mentions' (noms des colonnes et types)\n",
    "print(\"\\nStructure de la table 'mentions' :\")\n",
    "mentions_structure = show_table_structure('mentions')\n",
    "display(mentions_structure)\n",
    "\n",
    "# Fermeture de l'engine SQLAlchemy\n",
    "engine.dispose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e66ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Connexion avec sqlalchemy pour %sql et pandas\n",
    "engine = create_engine(f\"sqlite:///{db_path}\")\n",
    "\n",
    "# Statistiques pour la table 'events'\n",
    "\n",
    "print(\"=== Statistiques descriptives pour la table 'events' ===\")\n",
    "\n",
    "## Charger les données de 'events' avec SQLAlchemy\n",
    "events_df = pd.read_sql_query(\"SELECT * FROM events\", engine)\n",
    "\n",
    "## Stats pour les colonnes numériques\n",
    "numeric_cols_events = ['GoldsteinScale', 'NumMentions', 'NumSources', 'NumArticles', \n",
    "                      'AvgTone']\n",
    "events_numeric_stats = events_df[numeric_cols_events].describe()\n",
    "print(\"\\nStatistiques pour les colonnes numériques :\")\n",
    "display(events_numeric_stats)\n",
    "\n",
    "## Stats pour les colonnes textuelles\n",
    "non_numeric_cols_events = ['ActionGeo_FullName', 'Themes']\n",
    "for col in non_numeric_cols_events:\n",
    "    print(f\"\\nFréquence des valeurs uniques pour '{col}' :\")\n",
    "    value_counts = events_df[col].value_counts().head(10)\n",
    "    display(value_counts)\n",
    "\n",
    "## Événements majeurs\n",
    "print(\"\\nTop 10 événements par nombre de mentions :\")\n",
    "top_events = events_df.nlargest(10, 'NumMentions')[['GLOBALEVENTID', 'SQLDATE', 'NumMentions', 'AvgTone']]\n",
    "print(top_events)\n",
    "\n",
    "print(\"\\nTop 10 événements par impact :\")\n",
    "top_impact = events_df.nlargest(10, 'GoldsteinScale')[['GLOBALEVENTID', 'SQLDATE', 'GoldsteinScale', 'AvgTone']]\n",
    "print(top_impact)\n",
    "\n",
    "# Statistiques pour la table 'mentions'\n",
    "\n",
    "print(\"\\n=== Statistiques descriptives pour la table 'mentions' ===\")\n",
    "\n",
    "## Charger les données de 'mentions' avec SQLAlchemy\n",
    "mentions_df = pd.read_sql_query(\"SELECT * FROM mentions\", engine)\n",
    "\n",
    "## Stats pour les colonnes numériques\n",
    "numeric_cols_mentions = ['Confidence', 'MentionDocTone']\n",
    "mentions_numeric_stats = mentions_df[numeric_cols_mentions].describe()\n",
    "print(\"\\nStatistiques pour les colonnes numériques :\")\n",
    "display(mentions_numeric_stats)\n",
    "\n",
    "## Stats pour les colonnes non numériques\n",
    "non_numeric_cols_mentions = ['GLOBALEVENTID','MentionType', 'MentionSourceName']\n",
    "for col in non_numeric_cols_mentions:\n",
    "    print(f\"\\nFréquence des valeurs uniques pour '{col}' :\")\n",
    "    value_counts = mentions_df[col].value_counts().head(10)\n",
    "    display(value_counts)\n",
    "\n",
    "# Fermeture de l'engine SQLAlchemy\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03023ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Configurer le style des graphes\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"deep\")\n",
    "\n",
    "# Connexion avec sqlalchemy pour %sql et pandas\n",
    "engine = create_engine(f\"sqlite:///{db_path}\")\n",
    "\n",
    "# Analyse temporelle pour la table 'events'\n",
    "\n",
    "print(\"=== Analyse temporelle pour la table 'events' ===\")\n",
    "\n",
    "## Fréquence des événements par mois\n",
    "events_freq_query = \"\"\"\n",
    "SELECT substr(SQLDATE, 1, 6) AS month, COUNT(*) AS event_count\n",
    "FROM events\n",
    "GROUP BY month\n",
    "ORDER BY month\n",
    "\"\"\"\n",
    "events_freq_df = pd.read_sql_query(events_freq_query, engine)\n",
    "\n",
    "## Graphique : Fréquence des événements par mois\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=events_freq_df, x='month', y='event_count', marker='o')\n",
    "plt.title(\"Nombre d'événements par mois\")\n",
    "plt.xlabel(\"Mois (YYYYMM)\")\n",
    "plt.ylabel(\"Nombre d'événements\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "## Évolution de GoldsteinScale, NumMentions, NumSources, NumArticles\n",
    "events_metrics_query = \"\"\"\n",
    "SELECT substr(SQLDATE, 1, 6) AS month,\n",
    "       AVG(GoldsteinScale) AS avg_goldstein,\n",
    "       SUM(NumMentions) AS total_mentions,\n",
    "       SUM(NumSources) AS total_sources,\n",
    "       SUM(NumArticles) AS total_articles\n",
    "FROM events\n",
    "GROUP BY month\n",
    "ORDER BY month\n",
    "\"\"\"\n",
    "events_metrics_df = pd.read_sql_query(events_metrics_query, engine)\n",
    "\n",
    "## Graphique : Évolution des métriques\n",
    "fig, axes = plt.subplots(3, 2, figsize=(14, 10), sharex=True)\n",
    "fig.suptitle(\"Évolution des métriques par mois (events)\")\n",
    "\n",
    "## GoldsteinScale\n",
    "sns.lineplot(data=events_metrics_df, x='month', y='avg_goldstein', marker='o', ax=axes[0, 0])\n",
    "axes[0, 0].set_title(\"Moyenne GoldsteinScale\")\n",
    "axes[0, 0].set_ylabel(\"Moyenne\")\n",
    "\n",
    "## Évolution de NumMentions\n",
    "sns.lineplot(data=events_metrics_df, x='month', y='total_mentions', marker='o', ax=axes[0, 1])\n",
    "axes[0, 1].set_title(\"Total NumMentions\")\n",
    "axes[0, 1].set_ylabel(\"Total\")\n",
    "\n",
    "## Évolution de NumSources\n",
    "sns.lineplot(data=events_metrics_df, x='month', y='total_sources', marker='o', ax=axes[1, 0])\n",
    "axes[1, 0].set_title(\"Total NumSources\")\n",
    "axes[1, 0].set_ylabel(\"Total\")\n",
    "\n",
    "## Évolution de NumArticles\n",
    "sns.lineplot(data=events_metrics_df, x='month', y='total_articles', marker='o', ax=axes[1, 1])\n",
    "axes[0, 1].set_title(\"Total NumArticles\")\n",
    "axes[0, 1].set_ylabel(\"Total\")\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.set_xlabel(\"Mois (YYYYMM)\")\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "# Analyse temporelle pour la table 'mentions'\n",
    "\n",
    "print(\"\\n=== Analyse temporelle pour la table 'mentions' ===\")\n",
    "\n",
    "## Fréquence des mentions par mois\n",
    "mentions_freq_query = \"\"\"\n",
    "SELECT substr(MentionTimeDate, 1, 6) AS month, COUNT(*) AS mention_count\n",
    "FROM mentions\n",
    "GROUP BY month\n",
    "ORDER BY month\n",
    "\"\"\"\n",
    "mentions_freq_df = pd.read_sql_query(mentions_freq_query, engine)\n",
    "\n",
    "## Graphique : Fréquence des mentions par mois\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=mentions_freq_df, x='month', y='mention_count', marker='o')\n",
    "plt.title(\"Nombre de mentions par mois\")\n",
    "plt.xlabel(\"Mois (YYYYMM)\")\n",
    "plt.ylabel(\"Nombre de mentions\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "## Évolution de MentionDocTone, Confidence\n",
    "mentions_metrics_query = \"\"\"\n",
    "SELECT substr(MentionTimeDate, 1, 6) AS month,\n",
    "       AVG(MentionDocTone) AS avg_doctone,\n",
    "       AVG(Confidence) AS avg_confidence\n",
    "FROM mentions\n",
    "GROUP BY month\n",
    "ORDER BY month\n",
    "\"\"\"\n",
    "mentions_metrics_df = pd.read_sql_query(mentions_metrics_query, engine)\n",
    "\n",
    "# Évolution des métriques\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 12), sharex=True)\n",
    "fig.suptitle(\"Évolution des métriques par mois (mentions)\")\n",
    "\n",
    "# Évolution de MentionDocTone\n",
    "sns.lineplot(data=mentions_metrics_df, x='month', y='avg_doctone', marker='o', ax=axes[0])\n",
    "axes[0].set_title(\"Moyenne MentionDocTone\")\n",
    "axes[0].set_ylabel(\"Moyenne\")\n",
    "\n",
    "# Évolution de Confidence\n",
    "sns.lineplot(data=mentions_metrics_df, x='month', y='avg_confidence', marker='o', ax=axes[1])\n",
    "axes[1].set_title(\"Moyenne Confidence\")\n",
    "axes[1].set_ylabel(\"Moyenne\")\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlabel(\"Mois (YYYYMM)\")\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "# Fermeture de l'engine SQLAlchemy\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bab8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connexion avec sqlalchemy pour %sql et pandas\n",
    "engine = create_engine(f\"sqlite:///{db_path}\")\n",
    "\n",
    "# Chargement des tables dans les DataFrames\n",
    "events_df = pd.read_sql_query(\"SELECT * FROM events\", engine)\n",
    "mentions_df = pd.read_sql_query(\"SELECT * FROM mentions\", engine)\n",
    "\n",
    "# Conversion de SQLDATE en datetime\n",
    "events_df['SQLDATE'] = pd.to_datetime(events_df['SQLDATE'], errors='coerce')\n",
    "\n",
    "## Sentiments : Distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(events_df['AvgTone'], bins=30, kde=True, label='Events AvgTone')\n",
    "sns.histplot(mentions_df['MentionDocTone'], bins=30, kde=True, label='Mentions DocTone', alpha=0.5)\n",
    "plt.title(\"Distribution des sentiments\")\n",
    "plt.xlabel(\"Tonalité\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## Sentiments : Evolution mensuel\n",
    "events_df['Month'] = events_df['SQLDATE'].dt.strftime('%Y')\n",
    "sentiment_by_month = events_df.groupby('Month')['AvgTone'].mean()\n",
    "\n",
    "# Trier les mois dans l'ordre chronologique\n",
    "sentiment_by_month = sentiment_by_month.sort_index()\n",
    "\n",
    "sentiment_by_month.plot(kind='bar', figsize=(10, 5), color='skyblue')\n",
    "plt.title(\"Sentiment moyen par mois au Bénin (Events)\")\n",
    "plt.ylabel(\"Tonalité moyenne (AvgTone)\")\n",
    "plt.xlabel(\"Mois\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Fermeture de l'engine SQLAlchemy\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f345f846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Connexion à la base\n",
    "conn = sqlite3.connect(db_path)\n",
    "engine = create_engine(f\"sqlite:///{db_path}\")\n",
    "\n",
    "# Chargement des données\n",
    "print(\"=== Chargement des données ===\")\n",
    "query = \"\"\"\n",
    "SELECT SQLDATE, GoldsteinScale, NumMentions, NumSources, NumArticles, \n",
    "       ActionGeo_FullName, Themes, AvgTone\n",
    "FROM events\n",
    "\"\"\"\n",
    "df = pd.read_sql_query(query, conn)\n",
    "df['SQLDATE'] = pd.to_datetime(df['SQLDATE'], format='%Y-%m-%d')\n",
    "\n",
    "\n",
    "print(\"=== Feature engineering ===\")\n",
    "df['year'] = df['SQLDATE'].dt.year\n",
    "df['month'] = df['SQLDATE'].dt.month\n",
    "df['day'] = df['SQLDATE'].dt.day\n",
    "\n",
    "# Visualisation de AvgTone\n",
    "print(\"=== Visualisation de AvgTone : Historique ===\")\n",
    "\n",
    "# Historique mensuel\n",
    "df['date_str'] = df['year'].astype(str) + '-' + df['month'].astype(str).str.zfill(2)\n",
    "monthly_historical = df.groupby('date_str')['AvgTone'].mean().reset_index()\n",
    "\n",
    "# Graphique Historique de AvgTone\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=monthly_historical, x='date_str', y='AvgTone', label='Historique (AvgTone)', color='blue')\n",
    "plt.title(\"Évolution de AvgTone (Historique) : Moyenne Mensuelle\")\n",
    "plt.xlabel(\"Date (YYYY-MM)\")\n",
    "plt.ylabel(\"AvgTone\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Fermeture de l'engine SQLAlchemy\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ad4618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connexion avec sqlite3\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Connexion avec sqlalchemy pour %sql\n",
    "engine = create_engine(f\"sqlite:///{db_path}\")\n",
    "\n",
    "# Chargement et Préparation des données\n",
    "\n",
    "print(\"=== Chargement et agrégation des données ===\")\n",
    "\n",
    "query_events = \"\"\"\n",
    "SELECT GLOBALEVENTID, AvgTone, Themes, ActionGeo_FullName, SQLDATE\n",
    "FROM events\n",
    "LIMIT 100\n",
    "\"\"\"\n",
    "df_events = pd.read_sql_query(query_events, conn)\n",
    "\n",
    "# Convertir SQLDATE en datetime\n",
    "df_events['SQLDATE'] = pd.to_datetime(df_events['SQLDATE'], format='%Y-%m-%d')\n",
    "\n",
    "# Extraire année et mois\n",
    "df_events['year'] = df_events['SQLDATE'].dt.year\n",
    "df_events['month'] = df_events['SQLDATE'].dt.month\n",
    "\n",
    "# Agréger MentionDocTone par GLOBALEVENTID\n",
    "query_mentions = \"\"\"\n",
    "SELECT GLOBALEVENTID,\n",
    "       MentionDocTone\n",
    "FROM mentions\n",
    "WHERE GLOBALEVENTID IN (SELECT GLOBALEVENTID FROM events LIMIT 100)\n",
    "\"\"\"\n",
    "df_mentions = pd.read_sql_query(query_mentions, conn)\n",
    "\n",
    "# Vérifier si des mentions ont été trouvées\n",
    "print(\"Nombre de mentions trouvées :\", len(df_mentions))\n",
    "print(\"Nombre de GLOBALEVENTID uniques dans mentions :\", df_mentions['GLOBALEVENTID'].nunique())\n",
    "\n",
    "# Calculer les statistiques de MentionDocTone avec Pandas\n",
    "if not df_mentions.empty:\n",
    "    mentions_stats = df_mentions.groupby('GLOBALEVENTID').agg({\n",
    "        'MentionDocTone': ['mean', 'min', 'max', 'std']\n",
    "    }).reset_index()\n",
    "    # Renommer les colonnes\n",
    "    mentions_stats.columns = ['GLOBALEVENTID', 'avg_mention_tone', 'min_mention_tone', 'max_mention_tone', 'std_mention_tone']\n",
    "else:\n",
    "    print(\"Aucune mention trouvée pour les GLOBALEVENTID sélectionnés.\")\n",
    "    # Créer un DataFrame vide avec les colonnes attendues\n",
    "    mentions_stats = pd.DataFrame(columns=['GLOBALEVENTID', 'avg_mention_tone', 'min_mention_tone', 'max_mention_tone', 'std_mention_tone'])\n",
    "\n",
    "# Joindre les deux DataFrames\n",
    "df = df_events.merge(mentions_stats, on='GLOBALEVENTID', how='left')\n",
    "\n",
    "# Vérifier les valeurs manquantes\n",
    "print(\"Valeurs manquantes :\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Remplacer les valeurs manquantes\n",
    "df['avg_mention_tone'] = df['avg_mention_tone'].fillna(0)\n",
    "df['min_mention_tone'] = df['min_mention_tone'].fillna(0)\n",
    "df['max_mention_tone'] = df['max_mention_tone'].fillna(0)\n",
    "df['std_mention_tone'] = df['std_mention_tone'].fillna(0)\n",
    "df['Themes'] = df['Themes'].fillna(\"Inconnu\")\n",
    "df['ActionGeo_FullName'] = df['ActionGeo_FullName'].fillna(\"Inconnu\")\n",
    "\n",
    "# Supprimer les lignes avec AvgTone ou SQLDATE manquant\n",
    "df = df.dropna(subset=['AvgTone', 'SQLDATE'])\n",
    "\n",
    "# Analyse des sentiments avec call_openai_api\n",
    "print(\"=== Analyse des sentiments ===\")\n",
    "\n",
    "# Fonction pour analyser le sentiment d'un événement\n",
    "def analyze_sentiment(row):\n",
    "    avg_tone = row['AvgTone']\n",
    "    themes = row['Themes']\n",
    "    location = row['ActionGeo_FullName']\n",
    "    avg_mention_tone = row['avg_mention_tone']\n",
    "    min_mention_tone = row['min_mention_tone']\n",
    "    max_mention_tone = row['max_mention_tone']\n",
    "    std_mention_tone = row['std_mention_tone']\n",
    "    year = row['year']\n",
    "    month = row['month']\n",
    "    \n",
    "    # Prompt pour analyse des sentimeents\n",
    "    prompt = f\"\"\"\n",
    "    Vous êtes un expert en analyse des données issues de GDELT (Global Database of Events, Language, and Tone), une base de données mondiale sur les événements médiatisés. Votre tâche est d'analyser le sentiment d'un événement en fonction de son AvgTone, de ses thèmes, de sa localisation, des tons des mentions individuelles (MentionDocTone), et de sa date.\n",
    "\n",
    "    Données de l'événement :\n",
    "    - AvgTone : {avg_tone} (score numérique, généralement entre -15 et +15, où négatif indique un ton défavorable, positif un ton favorable, et près de 0 un ton neutre).\n",
    "    - Thèmes : {themes} (catégorie décrivant la nature de l'événement, ex. POLITIQUE, CONFLIT, CÉLÉBRATION).\n",
    "    - Localisation : {location} (lieu géographique de l'événement).\n",
    "    - MentionDocTone (ton des articles individuels) :\n",
    "      - Moyenne : {avg_mention_tone}\n",
    "      - Minimum : {min_mention_tone}\n",
    "      - Maximum : {max_mention_tone}\n",
    "      - Écart-type : {std_mention_tone} (indique la variabilité des tons des mentions).\n",
    "    - Date : Année {year}, Mois {month} (contexte temporel de l'événement).\n",
    "\n",
    "    Instructions :\n",
    "    1. Déterminez le sentiment de l'événement : \"Positif\", \"Neutre\" ou \"Négatif\".\n",
    "    2. Fournissez une explication concise traduidant pourquoi ce sentiment a été attribué, en tenant compte du contexte GDELT (ex. biais médiatiques, nature des thèmes, impact de la localisation, variabilité des MentionDocTone, et contexte temporel).\n",
    "    3. Comparez AvgTone et MentionDocTone pour identifier d'éventuelles incohérences ou polarisations, et mentionnez l'influence possible de la date (ex. événements mondiaux majeurs à cette période).\n",
    "    4. Structurez la réponse comme suit :\n",
    "       Sentiment : [Positif/Neutre/Négatif]\n",
    "       Explication : [Votre explication]\n",
    "\n",
    "    Exemple :\n",
    "    Sentiment : Positif\n",
    "    Explication : Un AvgTone de 5.0 et une moyenne MentionDocTone de 4.8 indiquent un ton médiatique favorable, renforcé par le thème CÉLÉBRATION en décembre 2020, probablement lié à des festivités de fin d'année. La faible variabilité (écart-type de 0.5) suggère une couverture cohérente.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Appeler l'API\n",
    "    try:\n",
    "        response = call_openai_api(prompt, max_tokens=500)\n",
    "        # Extraire le sentiment et l'explication\n",
    "        sentiment = response.split(\"Sentiment : \")[1].split(\"\\n\")[0].strip()\n",
    "        explanation = response.split(\"Explication : \")[1].strip()\n",
    "        return pd.Series([sentiment, explanation], index=['Sentiment', 'Explanation'])\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur pour GLOBALEVENTID {row['GLOBALEVENTID']}: {e}\")\n",
    "        return pd.Series(['Inconnu', f'Erreur API: {str(e)}'], index=['Sentiment', 'Explanation'])\n",
    "\n",
    "# Appliquer l'analyse à chaque ligne\n",
    "df[['Sentiment', 'Explanation']] = df.apply(analyze_sentiment, axis=1)\n",
    "\n",
    "# Résumé des sentiments\n",
    "print(\"=== Résumé des sentiments ===\")\n",
    "\n",
    "# Compter les sentiments\n",
    "sentiment_counts = df['Sentiment'].value_counts()\n",
    "print(\"\\nRépartition des sentiments :\")\n",
    "print(sentiment_counts)\n",
    "\n",
    "# Moyenne de AvgTone et avg_mention_tone par sentiment\n",
    "sentiment_summary = df.groupby('Sentiment')[['AvgTone', 'avg_mention_tone']].mean()\n",
    "print(\"\\nMoyennes de AvgTone et avg_mention_tone par sentiment :\")\n",
    "print(sentiment_summary)\n",
    "\n",
    "# Analyse temporelle\n",
    "\n",
    "print(\"=== Analyse temporelle ===\")\n",
    "\n",
    "# Répartition des sentiments par année\n",
    "sentiment_by_year = df.groupby(['year', 'Sentiment']).size().unstack(fill_value=0)\n",
    "sentiment_by_year = sentiment_by_year.div(sentiment_by_year.sum(axis=1), axis=0)  # Normaliser en proportions\n",
    "print(\"\\nRépartition des sentiments par année (proportions) :\")\n",
    "print(sentiment_by_year)\n",
    "\n",
    "# Moyenne de AvgTone et avg_mention_tone par année\n",
    "tone_by_year = df.groupby('year')[['AvgTone', 'avg_mention_tone']].mean()\n",
    "print(\"\\nMoyenne de AvgTone et avg_mention_tone par année :\")\n",
    "print(tone_by_year)\n",
    "\n",
    "# Visualisation des sentiments\n",
    "print(\"=== Visualisation ===\")\n",
    "\n",
    "# Répartition des sentiments par année\n",
    "plt.figure(figsize=(10, 6))\n",
    "sentiment_by_year.plot(kind='bar', stacked=True, colormap='viridis')\n",
    "plt.title(\"Répartition des sentiments par année (GDELT)\")\n",
    "plt.xlabel(\"Année\")\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.legend(title=\"Sentiment\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Évolution de AvgTone et avg_mention_tone par mois\n",
    "df['year_month'] = df['SQLDATE'].dt.to_period('M')\n",
    "tone_by_month = df.groupby('year_month')[['AvgTone', 'avg_mention_tone']].mean()\n",
    "plt.figure(figsize=(12, 6))\n",
    "tone_by_month.plot()\n",
    "plt.title(\"Évolution de AvgTone et MentionDocTone moyen par mois (GDELT)\")\n",
    "plt.xlabel(\"Date (YYYY-MM)\")\n",
    "plt.ylabel(\"Ton\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Répartition des sentiments\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=df, x='Sentiment', order=['Positif', 'Neutre', 'Négatif', 'Inconnu'])\n",
    "plt.title(\"Répartition des sentiments des événements (GDELT)\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Nombre d'événements\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Graphique : AvgTone vs avg_mention_tone par sentiment\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.scatterplot(data=df, x='AvgTone', y='avg_mention_tone', hue='Sentiment', style='Sentiment')\n",
    "plt.title(\"AvgTone vs MentionDocTone moyen par sentiment (GDELT)\")\n",
    "plt.xlabel(\"AvgTone\")\n",
    "plt.ylabel(\"MentionDocTone moyen\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Répartition des sentiments par mois (en proportion)\n",
    "sentiment_by_month = df.groupby(['year_month', 'Sentiment']).size().unstack(fill_value=0)\n",
    "sentiment_by_month = sentiment_by_month.div(sentiment_by_month.sum(axis=1), axis=0)\n",
    "\n",
    "# Evolution des sentiments dans le temps\n",
    "plt.figure(figsize=(12, 6))\n",
    "sentiment_by_month.plot(marker='o')\n",
    "plt.title(\"Évolution temporelle des sentiments (par mois)\")\n",
    "plt.xlabel(\"Date (YYYY-MM)\")\n",
    "plt.ylabel(\"Proportion (%)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Créer une matrice année/mois pour AvgTone\n",
    "pivot_heatmap = df.pivot_table(values='AvgTone', index='year', columns='month', aggfunc='mean')\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(pivot_heatmap, annot=True, fmt=\".1f\", cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Carte thermique de AvgTone (année vs mois)\")\n",
    "plt.xlabel(\"Mois\")\n",
    "plt.ylabel(\"Année\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Extrait les 5 thèmes les plus fréquents\n",
    "top_themes = df['Themes'].value_counts().head(5).index\n",
    "\n",
    "# Courbes d’AvgTone par thème\n",
    "plt.figure(figsize=(12, 6))\n",
    "for theme in top_themes:\n",
    "    subset = df[df['Themes'] == theme]\n",
    "    tone_by_theme = subset.groupby('year_month')['AvgTone'].mean()\n",
    "    plt.plot(tone_by_theme.index.astype(str), tone_by_theme.values, label=theme)\n",
    "\n",
    "\n",
    "# Sauvegarde du DataFrame avec les sentiments\n",
    "print(\"=== Sauvegarde des résultats ===\")\n",
    "\n",
    "# Dossier de destination de l'analyse des sentiments\n",
    "csv_output = \"/home/pionner02/Pionner02 UlChris-Project/data/event_sentiment_analysis_gdelt_with_mentions_temporal.csv\"\n",
    "\n",
    "df.to_csv(csv_output, index=False, encoding=\"utf-8\")\n",
    "print(\"Résultats sauvegardés dans 'event_sentiment_analysis_gdelt_with_mentions_temporal.csv'\")\n",
    "\n",
    "# Fermeture de la connexion\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1df908a",
   "metadata": {},
   "source": [
    "## Dashboard\n",
    "\n",
    "Ce tableau de bord vous propose une exploration interactive de ces données, combinant événements et mentions médiatiques, enrichies par des filtres temporels, géographiques et thématiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c328aaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_events shape: (10000, 11)\n",
      "df_mentions shape: (10000, 6)\n",
      "df_events null counts:\n",
      " GLOBALEVENTID            0\n",
      "SQLDATE                  0\n",
      "GoldsteinScale           0\n",
      "NumMentions              0\n",
      "NumSources               0\n",
      "NumArticles              0\n",
      "AvgTone                  0\n",
      "ActionGeo_FullName       0\n",
      "ActionGeo_Lat            0\n",
      "ActionGeo_Long           0\n",
      "Themes                9180\n",
      "dtype: int64\n",
      "df_mentions null counts:\n",
      " GLOBALEVENTID        0\n",
      "MentionTimeDate      0\n",
      "MentionSourceName    0\n",
      "MentionIdentifier    0\n",
      "Confidence           0\n",
      "MentionDocTone       0\n",
      "dtype: int64\n",
      "df_merged shape: (10131, 26)\n",
      "df_merged head:\n",
      "    GLOBALEVENTID    SQLDATE  GoldsteinScale  NumMentions  NumSources  \\\n",
      "0     1238864555 2025-04-19           -10.0           15           2   \n",
      "1     1239269408 2025-04-21           -10.0           16           2   \n",
      "2     1117208340 2023-07-26            -2.0           30           3   \n",
      "3     1117210338 2023-07-26             3.4           12           1   \n",
      "4     1124580946 2023-09-03             3.4           12           2   \n",
      "\n",
      "   NumArticles   AvgTone              ActionGeo_FullName  ActionGeo_Lat  \\\n",
      "0           15 -9.746639  Koudou, Benin (general), Benin        10.8945   \n",
      "1           16 -3.942652                           Benin         9.5000   \n",
      "2           30 -4.848485                           Benin         9.5000   \n",
      "3           12  4.403409                           Benin         9.5000   \n",
      "4           12  2.535821                           Benin         9.5000   \n",
      "\n",
      "   ActionGeo_Long  ... MentionTimeDate  MentionSourceName  MentionIdentifier  \\\n",
      "0         1.16328  ...             NaT                                         \n",
      "1         2.25000  ...             NaT                                         \n",
      "2         2.25000  ...             NaT                                         \n",
      "3         2.25000  ...             NaT                                         \n",
      "4         2.25000  ...             NaT                                         \n",
      "\n",
      "   Confidence  MentionDocTone  Year_y Quarter_y Month_y Week_y  Day_y  \n",
      "0         0.0             0.0     NaN       NaN     NaN   <NA>    NaN  \n",
      "1         0.0             0.0     NaN       NaN     NaN   <NA>    NaN  \n",
      "2         0.0             0.0     NaN       NaN     NaN   <NA>    NaN  \n",
      "3         0.0             0.0     NaN       NaN     NaN   <NA>    NaN  \n",
      "4         0.0             0.0     NaN       NaN     NaN   <NA>    NaN  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "df_merged null counts:\n",
      " GLOBALEVENTID            0\n",
      "SQLDATE                  0\n",
      "GoldsteinScale           0\n",
      "NumMentions              0\n",
      "NumSources               0\n",
      "NumArticles              0\n",
      "AvgTone                  0\n",
      "ActionGeo_FullName       0\n",
      "ActionGeo_Lat            0\n",
      "ActionGeo_Long           0\n",
      "Themes                   0\n",
      "Year_x                   0\n",
      "Quarter_x                0\n",
      "Month_x                  0\n",
      "Week_x                   0\n",
      "Day_x                    0\n",
      "MentionTimeDate       9550\n",
      "MentionSourceName        0\n",
      "MentionIdentifier        0\n",
      "Confidence               0\n",
      "MentionDocTone           0\n",
      "Year_y                9550\n",
      "Quarter_y             9550\n",
      "Month_y               9550\n",
      "Week_y                9550\n",
      "Day_y                 9550\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://0.0.0.0:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x71e47008bdc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial filtered_df shape: (10131, 26)\n",
      "Final filtered_df shape: (10131, 26)\n",
      "Final filtered_df head:\n",
      "    GLOBALEVENTID    SQLDATE  GoldsteinScale  NumMentions  NumSources  \\\n",
      "0     1238864555 2025-04-19           -10.0           15           2   \n",
      "1     1239269408 2025-04-21           -10.0           16           2   \n",
      "2     1117208340 2023-07-26            -2.0           30           3   \n",
      "3     1117210338 2023-07-26             3.4           12           1   \n",
      "4     1124580946 2023-09-03             3.4           12           2   \n",
      "\n",
      "   NumArticles   AvgTone              ActionGeo_FullName  ActionGeo_Lat  \\\n",
      "0           15 -9.746639  Koudou, Benin (general), Benin        10.8945   \n",
      "1           16 -3.942652                           Benin         9.5000   \n",
      "2           30 -4.848485                           Benin         9.5000   \n",
      "3           12  4.403409                           Benin         9.5000   \n",
      "4           12  2.535821                           Benin         9.5000   \n",
      "\n",
      "   ActionGeo_Long  ... MentionTimeDate  MentionSourceName  MentionIdentifier  \\\n",
      "0         1.16328  ...             NaT                                         \n",
      "1         2.25000  ...             NaT                                         \n",
      "2         2.25000  ...             NaT                                         \n",
      "3         2.25000  ...             NaT                                         \n",
      "4         2.25000  ...             NaT                                         \n",
      "\n",
      "   Confidence  MentionDocTone  Year_y Quarter_y Month_y Week_y  Day_y  \n",
      "0         0.0             0.0     NaN       NaN     NaN   <NA>    NaN  \n",
      "1         0.0             0.0     NaN       NaN     NaN   <NA>    NaN  \n",
      "2         0.0             0.0     NaN       NaN     NaN   <NA>    NaN  \n",
      "3         0.0             0.0     NaN       NaN     NaN   <NA>    NaN  \n",
      "4         0.0             0.0     NaN       NaN     NaN   <NA>    NaN  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "Themes table data: [{'Theme': '', 'Count': 9302, 'AvgTone': -1.22}, {'Theme': 'POLITIQUE', 'Count': 105, 'AvgTone': -2.42}, {'Theme': 'CRISE SOCIALE', 'Count': 36, 'AvgTone': -1.56}, {'Theme': 'CRIME', 'Count': 25, 'AvgTone': -4.85}, {'Theme': 'CULTURE TRADITIONNELLE', 'Count': 12, 'AvgTone': 5.84}]\n"
     ]
    }
   ],
   "source": [
    "import dash\n",
    "from dash import dcc, html, dash_table\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Chemin vers la base de données\n",
    "output_dir = \"/home/pionner02/Pionner02 UlChris-Project/data\"\n",
    "db_path = os.path.join(output_dir, 'gdelt_benin.db')\n",
    "\n",
    "# Connexion à la base SQLite\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Chargement des données\n",
    "query_events = \"\"\"\n",
    "SELECT GLOBALEVENTID, SQLDATE, GoldsteinScale, NumMentions, NumSources, NumArticles, AvgTone,\n",
    "       ActionGeo_FullName, ActionGeo_Lat, ActionGeo_Long, Themes\n",
    "FROM events\n",
    "WHERE ActionGeo_Lat IS NOT NULL AND ActionGeo_Long IS NOT NULL\n",
    "LIMIT 10000  -- Limiter pour accélérer\n",
    "\"\"\"\n",
    "query_mentions = \"\"\"\n",
    "SELECT GLOBALEVENTID, MentionTimeDate, MentionSourceName, MentionIdentifier, Confidence, MentionDocTone\n",
    "FROM mentions\n",
    "LIMIT 10000  -- Limiter pour accélérer\n",
    "\"\"\"\n",
    "df_events = pd.read_sql_query(query_events, conn)\n",
    "df_mentions = pd.read_sql_query(query_mentions, conn)\n",
    "conn.close()\n",
    "\n",
    "# Débogage des données\n",
    "print(\"df_events shape:\", df_events.shape)\n",
    "print(\"df_mentions shape:\", df_mentions.shape)\n",
    "print(\"df_events null counts:\\n\", df_events.isnull().sum())\n",
    "print(\"df_mentions null counts:\\n\", df_mentions.isnull().sum())\n",
    "\n",
    "# Nettoyage des données\n",
    "df_events['Themes'] = df_events['Themes'].fillna('').astype(str)\n",
    "df_events['NumMentions'] = pd.to_numeric(df_events['NumMentions'], errors='coerce').fillna(0)\n",
    "df_events['NumSources'] = pd.to_numeric(df_events['NumSources'], errors='coerce').fillna(0)\n",
    "df_events['NumArticles'] = pd.to_numeric(df_events['NumArticles'], errors='coerce').fillna(0)\n",
    "df_events['GoldsteinScale'] = pd.to_numeric(df_events['GoldsteinScale'], errors='coerce').fillna(0)\n",
    "df_events['AvgTone'] = pd.to_numeric(df_events['AvgTone'], errors='coerce').fillna(0)\n",
    "df_mentions['Confidence'] = pd.to_numeric(df_mentions['Confidence'], errors='coerce').fillna(0)\n",
    "df_mentions['MentionDocTone'] = pd.to_numeric(df_mentions['MentionDocTone'], errors='coerce').fillna(0)\n",
    "\n",
    "# Conversion des dates\n",
    "df_events['SQLDATE'] = pd.to_datetime(df_events['SQLDATE'], format='%Y-%m-%d', errors='coerce')\n",
    "df_mentions['MentionTimeDate'] = pd.to_datetime(df_mentions['MentionTimeDate'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "\n",
    "# Hiérarchies de dates\n",
    "df_events['Year'] = df_events['SQLDATE'].dt.year\n",
    "df_events['Quarter'] = df_events['SQLDATE'].dt.quarter\n",
    "df_events['Month'] = df_events['SQLDATE'].dt.month\n",
    "df_events['Week'] = df_events['SQLDATE'].dt.isocalendar().week\n",
    "df_events['Day'] = df_events['SQLDATE'].dt.day\n",
    "\n",
    "df_mentions['Year'] = df_mentions['MentionTimeDate'].dt.year\n",
    "df_mentions['Quarter'] = df_mentions['MentionTimeDate'].dt.quarter\n",
    "df_mentions['Month'] = df_mentions['MentionTimeDate'].dt.month\n",
    "df_mentions['Week'] = df_mentions['MentionTimeDate'].dt.isocalendar().week\n",
    "df_mentions['Day'] = df_mentions['MentionTimeDate'].dt.day\n",
    "\n",
    "# Fusionner les données pour le tableau\n",
    "df_merged = pd.merge(df_events, df_mentions, on='GLOBALEVENTID', how='left')  # Utiliser left pour éviter vide\n",
    "df_merged.fillna({'Themes': '', 'MentionSourceName': '', 'MentionIdentifier': '', 'Confidence': 0, 'MentionDocTone': 0}, inplace=True)\n",
    "print(\"df_merged shape:\", df_merged.shape)\n",
    "print(\"df_merged head:\\n\", df_merged.head())\n",
    "print(\"df_merged null counts:\\n\", df_merged.isnull().sum())\n",
    "\n",
    "# Options pour les filtres\n",
    "years = sorted(df_events['Year'].dropna().unique())\n",
    "quarters = [1, 2, 3, 4]\n",
    "months = sorted(df_events['Month'].dropna().unique())\n",
    "weeks = sorted(df_events['Week'].dropna().unique())\n",
    "themes = pd.Series(df_events['Themes'].str.split(';', expand=True).stack().unique()).dropna()\n",
    "sources = df_mentions['MentionSourceName'].dropna().unique()\n",
    "\n",
    "# Initialisation de l'application Dash\n",
    "app = dash.Dash(__name__)\n",
    "app.scripts.config.serve_locally = True\n",
    "app.css.config.serve_locally = True\n",
    "\n",
    "# Style CSS pour les cadres\n",
    "box_style = {\n",
    "    'border': '1px solid #ccc',\n",
    "    'borderRadius': '5px',\n",
    "    'padding': '10px',\n",
    "    'margin': '10px',\n",
    "    'textAlign': 'center',\n",
    "    'boxShadow': '2px 2px 5px rgba(0,0,0,0.1)',\n",
    "    'width': '200px',\n",
    "    'display': 'inline-block'\n",
    "}\n",
    "\n",
    "# Layout du dashboard\n",
    "app.layout = html.Div([\n",
    "    html.H1('Dashboard des Événements et Mentions', style={'textAlign': 'center'}),\n",
    "\n",
    "    # Filtres\n",
    "    html.Div([\n",
    "        html.H3('Filtres SQLDATE'),\n",
    "        html.Label('Année'),\n",
    "        dcc.Dropdown(id='sql-year', options=[{'label': y, 'value': y} for y in years], multi=True, style={'width': '50%'}),\n",
    "        html.Label('Trimestre'),\n",
    "        dcc.Dropdown(id='sql-quarter', options=[{'label': q, 'value': q} for q in quarters], multi=True, style={'width': '50%'}),\n",
    "        html.Label('Mois'),\n",
    "        dcc.Dropdown(id='sql-month', options=[{'label': m, 'value': m} for m in months], multi=True, style={'width': '50%'}),\n",
    "        html.Label('Semaine'),\n",
    "        dcc.Dropdown(id='sql-week', options=[{'label': w, 'value': w} for w in weeks], multi=True, style={'width': '50%'}),\n",
    "    ], style={'width': '45%', 'display': 'inline-block', 'verticalAlign': 'top'}),\n",
    "\n",
    "    html.Div([\n",
    "        html.H3('Filtres MentionTimeDate'),\n",
    "        html.Label('Année'),\n",
    "        dcc.Dropdown(id='mention-year', options=[{'label': y, 'value': y} for y in years], multi=True, style={'width': '50%'}),\n",
    "        html.Label('Trimestre'),\n",
    "        dcc.Dropdown(id='mention-quarter', options=[{'label': q, 'value': q} for q in quarters], multi=True, style={'width': '50%'}),\n",
    "        html.Label('Mois'),\n",
    "        dcc.Dropdown(id='mention-month', options=[{'label': m, 'value': m} for m in months], multi=True, style={'width': '50%'}),\n",
    "        html.Label('Semaine'),\n",
    "        dcc.Dropdown(id='mention-week', options=[{'label': w, 'value': w} for w in weeks], multi=True, style={'width': '50%'}),\n",
    "    ], style={'width': '45%', 'display': 'inline-block', 'verticalAlign': 'top'}),\n",
    "\n",
    "    html.Div([\n",
    "        html.H3('Filtres Additionnels'),\n",
    "        html.Label('Thèmes'),\n",
    "        dcc.Dropdown(id='themes-filter', options=[{'label': t, 'value': t} for t in themes], multi=True, style={'width': '50%'}),\n",
    "        html.Label('Source de Mention'),\n",
    "        dcc.Dropdown(id='source-filter', options=[{'label': s, 'value': s} for s in sources], multi=True, style={'width': '50%'}),\n",
    "    ], style={'margin': '20px'}),\n",
    "\n",
    "    # Tableau principal\n",
    "    html.H3('Tableau des Données'),\n",
    "    dash_table.DataTable(\n",
    "        id='data-table',\n",
    "        columns=[\n",
    "            {'name': 'GLOBALEVENTID', 'id': 'GLOBALEVENTID'},\n",
    "            {'name': 'GoldsteinScale', 'id': 'GoldsteinScale'},\n",
    "            {'name': 'NumMentions', 'id': 'NumMentions'},\n",
    "            {'name': 'NumSources', 'id': 'NumSources'},\n",
    "            {'name': 'NumArticles', 'id': 'NumArticles'},\n",
    "            {'name': 'AvgTone', 'id': 'AvgTone'},\n",
    "            {'name': 'MentionSourceName', 'id': 'MentionSourceName'},\n",
    "            {'name': 'MentionIdentifier', 'id': 'MentionIdentifier'},\n",
    "            {'name': 'Confidence', 'id': 'Confidence'},\n",
    "            {'name': 'MentionDocTone', 'id': 'MentionDocTone'},\n",
    "        ],\n",
    "        page_size=10,\n",
    "        style_table={'overflowX': 'auto'},\n",
    "        style_cell={'textAlign': 'left', 'minWidth': '100px', 'maxWidth': '300px', 'whiteSpace': 'normal'},\n",
    "        data=df_merged[[\n",
    "            'GLOBALEVENTID', 'GoldsteinScale', 'NumMentions', 'NumSources', 'NumArticles',\n",
    "            'AvgTone', 'MentionSourceName', 'MentionIdentifier', 'Confidence', 'MentionDocTone'\n",
    "        ]].head(100).to_dict('records'),\n",
    "    ),\n",
    "\n",
    "    # Carte géographique\n",
    "    html.H3('Carte des Événements'),\n",
    "    dcc.Graph(id='geo-map'),\n",
    "\n",
    "    # Cadres pour NumMentions, NumSources, NumArticles\n",
    "    html.H3('Métriques des Mentions, Sources et Articles'),\n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            html.H4('Total Mentions'),\n",
    "            html.P(id='num-mentions', style={'fontSize': '20px', 'fontWeight': 'bold'})\n",
    "        ], style=box_style),\n",
    "        html.Div([\n",
    "            html.H4('Total Sources'),\n",
    "            html.P(id='num-sources', style={'fontSize': '20px', 'fontWeight': 'bold'})\n",
    "        ], style=box_style),\n",
    "        html.Div([\n",
    "            html.H4('Total Articles'),\n",
    "            html.P(id='num-articles', style={'fontSize': '20px', 'fontWeight': 'bold'})\n",
    "        ], style=box_style),\n",
    "    ], style={'textAlign': 'center'}),\n",
    "\n",
    "    # Tableau pour Top 5 Themes\n",
    "    html.H3('Top 5 Thèmes avec AvgTone'),\n",
    "    dash_table.DataTable(\n",
    "        id='themes-table',\n",
    "        columns=[\n",
    "            {'name': 'Thème', 'id': 'Theme'},\n",
    "            {'name': 'Occurrences', 'id': 'Count'},\n",
    "            {'name': 'AvgTone Moyen', 'id': 'AvgTone'}\n",
    "        ],\n",
    "        page_size=5,\n",
    "        style_table={'overflowX': 'auto'},\n",
    "        style_cell={'textAlign': 'left', 'minWidth': '100px', 'maxWidth': '300px', 'whiteSpace': 'normal'},\n",
    "        data=df_merged['Themes'].str.split(';', expand=True).stack().value_counts().head(5).reset_index().rename(columns={'index': 'Theme', 'count': 'Count'}).assign(AvgTone=0).to_dict('records'),  # Données par défaut\n",
    "    ),\n",
    "\n",
    "    # Cadres pour moyennes des métriques\n",
    "    html.H3('Moyennes des Métriques'),\n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            html.H4('Moyenne GoldsteinScale'),\n",
    "            html.P(id='avg-goldstein', style={'fontSize': '20px', 'fontWeight': 'bold'})\n",
    "        ], style=box_style),\n",
    "        html.Div([\n",
    "            html.H4('Moyenne AvgTone'),\n",
    "            html.P(id='avg-tone', style={'fontSize': '20px', 'fontWeight': 'bold'})\n",
    "        ], style=box_style),\n",
    "        html.Div([\n",
    "            html.H4('Moyenne Confidence'),\n",
    "            html.P(id='avg-confidence', style={'fontSize': '20px', 'fontWeight': 'bold'})\n",
    "        ], style=box_style),\n",
    "        html.Div([\n",
    "            html.H4('Moyenne MentionDocTone'),\n",
    "            html.P(id='avg-mention-tone', style={'fontSize': '20px', 'fontWeight': 'bold'})\n",
    "        ], style=box_style),\n",
    "    ], style={'textAlign': 'center'}),\n",
    "])\n",
    "\n",
    "# Callback pour mettre à jour tous les composants\n",
    "@app.callback(\n",
    "    [Output('data-table', 'data'),\n",
    "     Output('geo-map', 'figure'),\n",
    "     Output('num-mentions', 'children'),\n",
    "     Output('num-sources', 'children'),\n",
    "     Output('num-articles', 'children'),\n",
    "     Output('themes-table', 'data'),\n",
    "     Output('avg-goldstein', 'children'),\n",
    "     Output('avg-tone', 'children'),\n",
    "     Output('avg-confidence', 'children'),\n",
    "     Output('avg-mention-tone', 'children')],\n",
    "    [Input('sql-year', 'value'),\n",
    "     Input('sql-quarter', 'value'),\n",
    "     Input('sql-month', 'value'),\n",
    "     Input('sql-week', 'value'),\n",
    "     Input('mention-year', 'value'),\n",
    "     Input('mention-quarter', 'value'),\n",
    "     Input('mention-month', 'value'),\n",
    "     Input('mention-week', 'value'),\n",
    "     Input('themes-filter', 'value'),\n",
    "     Input('source-filter', 'value')]\n",
    ")\n",
    "def update_dashboard(sql_year, sql_quarter, sql_month, sql_week,\n",
    "                    mention_year, mention_quarter, mention_month, mention_week,\n",
    "                    themes, sources):\n",
    "    filtered_df = df_merged.copy()\n",
    "    \n",
    "    print(\"Initial filtered_df shape:\", filtered_df.shape)\n",
    "    \n",
    "    # Filtres SQLDATE\n",
    "    if sql_year:\n",
    "        filtered_df = filtered_df[filtered_df['Year_x'].isin(sql_year) & filtered_df['Year_x'].notna()]\n",
    "    if sql_quarter:\n",
    "        filtered_df = filtered_df[filtered_df['Quarter_x'].isin(sql_quarter) & filtered_df['Quarter_x'].notna()]\n",
    "    if sql_month:\n",
    "        filtered_df = filtered_df[filtered_df['Month_x'].isin(sql_month) & filtered_df['Month_x'].notna()]\n",
    "    if sql_week:\n",
    "        filtered_df = filtered_df[filtered_df['Week_x'].isin(sql_week) & filtered_df['Week_x'].notna()]\n",
    "    \n",
    "    # Filtres MentionTimeDate\n",
    "    if mention_year:\n",
    "        filtered_df = filtered_df[filtered_df['Year_y'].isin(mention_year) & filtered_df['Year_y'].notna()]\n",
    "    if mention_quarter:\n",
    "        filtered_df = filtered_df[filtered_df['Quarter_y'].isin(mention_quarter) & filtered_df['Quarter_y'].notna()]\n",
    "    if mention_month:\n",
    "        filtered_df = filtered_df[filtered_df['Month_y'].isin(mention_month) & filtered_df['Month_y'].notna()]\n",
    "    if mention_week:\n",
    "        filtered_df = filtered_df[filtered_df['Week_y'].isin(mention_week) & filtered_df['Week_y'].notna()]\n",
    "    \n",
    "    # Filtres Thèmes\n",
    "    if themes:\n",
    "        filtered_df = filtered_df[filtered_df['Themes'].str.contains('|'.join(themes), na=False)]\n",
    "    \n",
    "    # Filtres Sources\n",
    "    if sources:\n",
    "        filtered_df = filtered_df[filtered_df['MentionSourceName'].isin(sources) & filtered_df['MentionSourceName'].notna()]\n",
    "    \n",
    "    print(\"Final filtered_df shape:\", filtered_df.shape)\n",
    "    print(\"Final filtered_df head:\\n\", filtered_df.head())\n",
    "    \n",
    "    # Tableau principal\n",
    "    table_data = filtered_df[[\n",
    "        'GLOBALEVENTID', 'GoldsteinScale', 'NumMentions', 'NumSources', 'NumArticles',\n",
    "        'AvgTone', 'MentionSourceName', 'MentionIdentifier', 'Confidence', 'MentionDocTone'\n",
    "    ]].to_dict('records')\n",
    "    \n",
    "    # Carte géographique\n",
    "    fig_map = px.scatter_geo(\n",
    "        filtered_df,\n",
    "        lat='ActionGeo_Lat',\n",
    "        lon='ActionGeo_Long',\n",
    "        hover_name='ActionGeo_FullName',\n",
    "        size='NumMentions',\n",
    "        color='AvgTone',\n",
    "        color_continuous_scale='RdBu',\n",
    "        title='Carte des Événements',\n",
    "        projection='natural earth'\n",
    "    )\n",
    "    fig_map.update_layout(\n",
    "        geo=dict(showframe=False, showcoastlines=True),\n",
    "        dragmode='zoom',\n",
    "        margin={'l': 0, 'r': 0, 't': 50, 'b': 0}\n",
    "    )\n",
    "    \n",
    "    # Sommes pour NumMentions, NumSources, NumArticles\n",
    "    total_mentions = f\"{int(filtered_df['NumMentions'].sum()):,}\" if not filtered_df['NumMentions'].empty else \"0\"\n",
    "    total_sources = f\"{int(filtered_df['NumSources'].sum()):,}\" if not filtered_df['NumSources'].empty else \"0\"\n",
    "    total_articles = f\"{int(filtered_df['NumArticles'].sum()):,}\" if not filtered_df['NumArticles'].empty else \"0\"\n",
    "    \n",
    "    # Tableau pour Top 5 Themes avec AvgTone\n",
    "    if not filtered_df.empty and filtered_df['Themes'].str.strip().ne('').any():\n",
    "        themes_data = filtered_df['Themes'].str.split(';', expand=True).stack().reset_index(drop=True)\n",
    "        themes_counts = themes_data.value_counts().head(5).reset_index()\n",
    "        themes_counts.columns = ['Theme', 'Count']\n",
    "        themes_avg_tone = []\n",
    "        for theme in themes_counts['Theme']:\n",
    "            theme_mask = filtered_df['Themes'].str.contains(theme, na=False)\n",
    "            avg_tone = filtered_df[theme_mask]['AvgTone'].mean() if theme_mask.any() else 0\n",
    "            themes_avg_tone.append(round(avg_tone, 2) if pd.notna(avg_tone) else 0)\n",
    "        themes_counts['AvgTone'] = themes_avg_tone\n",
    "    else:\n",
    "        themes_counts = pd.DataFrame({'Theme': ['Aucun thème'], 'Count': [0], 'AvgTone': [0]})\n",
    "    themes_table_data = themes_counts.to_dict('records')\n",
    "    print(\"Themes table data:\", themes_table_data)\n",
    "    \n",
    "    # Moyennes des métriques\n",
    "    avg_goldstein = round(filtered_df['GoldsteinScale'].mean(), 2) if not filtered_df['GoldsteinScale'].empty else 0\n",
    "    avg_tone = round(filtered_df['AvgTone'].mean(), 2) if not filtered_df['AvgTone'].empty else 0\n",
    "    avg_confidence = round(filtered_df['Confidence'].mean(), 2) if not filtered_df['Confidence'].empty else 0\n",
    "    avg_mention_tone = round(filtered_df['MentionDocTone'].mean(), 2) if not filtered_df['MentionDocTone'].empty else 0\n",
    "    \n",
    "    return (\n",
    "        table_data,\n",
    "        fig_map,\n",
    "        total_mentions,\n",
    "        total_sources,\n",
    "        total_articles,\n",
    "        themes_table_data,\n",
    "        str(avg_goldstein),\n",
    "        str(avg_tone),\n",
    "        str(avg_confidence),\n",
    "        str(avg_mention_tone)\n",
    "    )\n",
    "\n",
    "# Lancement du serveur\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=False, host='0.0.0.0', port=8050)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
